import random
import numpy
import pandas as pd
#from deap import algorithms
#from deap import base
#from deap import creator
#from deap import tools
import multiprocessing
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import argparse
#from scoop import futures
import hashlib
import os
%matplotlib inline
from pandas import DataFrame
from sklearn.linear_model import LogisticRegression


df = pd.read_csv('./class-Neo4j.csv')
print(df.shape)
X= df.iloc[:,0:97]
y = df.iloc[:,-1]

#CSV FIlE CONVERSION
from sklearn.preprocessing import LabelEncoder
X_raw = df[['Hash','LongName']]
X = pd.DataFrame()
for col in X_raw:
    le = LabelEncoder()
    X[col] = le.fit_transform(X_raw[col].astype(str))

new_X=df.iloc[:,2:97]
data_new = pd.concat([X, new_X], ignore_index=False, sort=False, axis=1)
# data_new.fillna(0, inplace=True)

data_new = data_new.iloc[:,0:97]

for column in data_new.columns:
    maxval = data_new[column].max()
    minval = data_new[column].min()    
    if(maxval == minval):
        data_new[column] = (data_new[column] - data_new[column].min()) / (data_new[column].max() - data_new[column].min()+ .000001)        
    else:
        data_new[column] = (data_new[column] - data_new[column].min()) / (data_new[column].max() - data_new[column].min())

data = pd.concat([data_new, y], ignore_index=False, sort=False, axis=1) 
data['Bugs'] = data['Bugs'].apply(lambda x : 1 if x != 0 else x)



import numpy

def crossover(parents, offspring_size):
    offspring = numpy.empty(offspring_size)
#     print('1. offspring shape: ', offspring.shape)
    # The point at which crossover takes place between two parents. Usually, it is at the center.
    crossover_point = numpy.uint8(offspring_size[1]/2)
#     print('2. Crossover point: ', crossover_point)
    for k in range(offspring_size[0]):
        # Index of the first parent to mate.
        parent1_idx = k%parents.shape[0]
#         print('3. parent1_idx: ', parent1_idx)
        # Index of the second parent to mate.
        parent2_idx = (k+1)%parents.shape[0]
#         print('4. parent2_idx: ', parent2_idx)
        # The new offspring will have its first half of its genes taken from the first parent.
        offspring[k, 0:crossover_point] = parents.iloc[parent1_idx, 0:crossover_point]
#         print('5. offspring[',k,', 0:',crossover_point,']: ', offspring[k, 0:crossover_point])
        # The new offspring will have its second half of its genes taken from the second parent.
        offspring[k, crossover_point:] = parents.iloc[parent2_idx, crossover_point:]
#         print('6. offspring[',k,',',crossover_point,':]: ', offspring[k, crossover_point:])
    return offspring

def mutation(offspring_crossover, num_mutations=1):
    mutations_counter = numpy.uint8(offspring_crossover.shape[1] / num_mutations)
    print('\n')
#     print('1. Mutation counter: ', mutations_counter)
    # Mutation changes a number of genes as defined by the num_mutations argument. The changes are random.
    for idx in range(offspring_crossover.shape[0]):
#         print('2. offspring_crossover.shape[0]: ', offspring_crossover.shape[0])
        gene_idx = mutations_counter - 1
        for mutation_num in range(num_mutations):
            # The random value to be added to the gene.
            random_value = numpy.random.uniform(-1.0, 1.0, 1)
            offspring_crossover[idx, gene_idx] = offspring_crossover[idx, gene_idx] + random_value
#             print('3. offspring_crossover[',idx,',',gene_idx,']: ', offspring_crossover[idx, gene_idx]+random_value, ' where the random value is: ', offspring_crossover[idx,gene_idx],' and ', random_value)
            gene_idx = gene_idx + mutations_counter
#             print('4. gene_idx: ', gene_idx+mutations_counter)

    return offspring_crossover


#This function has not been used.
def select_mating_pool(population, highest_point, num_parents):

    # Selecting the best individuals in the current generation as parents for producing the offspring of the next generation.
    parents = numpy.empty((num_parents, new_population.shape[1]))
#     print(new_population)
    for parent_num in range(num_parents):

        max_fitness_idx = numpy.where(fitness == numpy.max(fitness))
#         print("max_fitness_idx: " + str(max_fitness_idx) )
        max_fitness_idx = max_fitness_idx[0][0]
#         print("max_fitness_idx values: " + str(max_fitness_idx))
#         print(fitness[max_fitness_idx])
        parents[parent_num, :] = new_population.iloc[max_fitness_idx, :]
#         print("parents[parent_num, :]: " + str(parents[parent_num, :]))
#         print('new_population.iloc[max_fitness_idx, :]: ' + str(new_population.iloc[max_fitness_idx, :]))
        fitness[max_fitness_idx] = -99999999999

    print('parents: ')
    print(parents)
    return parents
    
    
    
# BLOCK STARTS
#Inputs
num_weights = 97
population = data.sample(frac=.1) 
# print(population)
member_in_pop = population.shape[0]
print(member_in_pop)
pop_size = (member_in_pop, num_weights)

num_parents_mating = 30


new_population = population.iloc[:,0:97]
num_generations = 100
#BLOCK ENDS

def distance(p0, p1):
    """ Calculate the distance between two hydrant """
#     print('distance: ' + str(math.sqrt((p0[0] - p1[0])**2 + (p0[1] - p1[1])**2)))
    dist = math.sqrt((p0[0] - p1[0])**2 + (p0[1] - p1[1])**2)
    return dist
# BLOCK ENDS



pop_multi = numpy.random.uniform(low=0, high=1.0, size=pop_size)
dataframe_new= DataFrame(pop_multi)
# print(pop_multi)

def cal_pop_fitness(dataframe_new,population):
    pop_multi = pd.DataFrame(dataframe_new).to_numpy()
    print('\n')
    fitness = []
    highest_point = []
    high_fit = 0
    weight = []
    temp_population = DataFrame()
    j=0
    parent = numpy.ones((1, num_weights))
    temp_fit = []
    index = []
    data_new = []
    tsnelist = []
    tsne_df = []
    res = zip()
    
    for i in range(member_in_pop):
        j=j+1
#         print(i)
        #pop
        x= population.iloc[:,0:97].multiply(pop_multi[i], axis=1)
        y=population.iloc[:,-1]
        data = pd.concat([x, y], ignore_index=False, sort=False, axis=1)
        data_new.append(data)
        from sklearn.manifold import TSNE
        tsne = TSNE(n_components=2, random_state=0, perplexity=7.0)
        tsne_obj= tsne.fit_transform(data)
        tsne_df1 = pd.DataFrame({'X':tsne_obj[:,0],
                            'Y':tsne_obj[:,1],
                           'bug':population.iloc[:,-1]})
        tsnelist.append(tsne_df1)
        
        X=tsne_df1.drop('bug', axis=1)
        y=tsne_df1['bug']

#         clf = make_pipeline(StandardScaler(),
#                 LinearSVC(random_state=0, tol=1e-5))
        forest = make_pipeline(StandardScaler(),
                    SGDClassifier(max_iter=1000, tol=1e-5))
        cv_results = cross_val_score(forest,X,y,cv=10)
        forest.fit(X, y)

        prediction = cross_val_predict(forest,X,y,cv=10)

        accuracy = metrics.accuracy_score(y, prediction)  
        precision = precision_score(y, prediction)
        recall = recall_score(y, prediction, average='binary')
 
        temp_fit.append(recall)
        index.append(i)

    res = zip(temp_fit,index)
    result = list(res)
    
    if(high_fit<max(temp_fit)):
        high_fit = max(temp_fit)
        fitness=temp_fit
        
    for i in range(member_in_pop):     
        if(high_fit == result[i][0]):
            j = result[i][1]
            temp_population = data_new[j]
            tsne_df = tsnelist[j]
            weight = pop_multi[j]
    
    
    ind = np.argpartition(temp_fit, -num_parents_mating)[-num_parents_mating:]
    
#     print('ind: ', ind)
    for i in ind:
        j = result[i][1]
#         print('j: ', j)
#         temp_population = data_new[j]
#        tsne_df = tsnelist[j]
#        weight = pop_multi[j]
        parent = np.vstack([parent, pop_multi[j]])
#         print('parent: ', parent)
    
     
    #parent = temp_population.iloc[:, 0:97]#.sample(num_parents_mating)
    parents = pd.DataFrame(parent)
    #print(parents)
#     print('parent shape: ', parent.shape)
#     print("fitness length:" + str(len(fitness)))
    
    return fitness, parents, tsne_df,weight, temp_population
    
    
  
 import numpy
import random
from pandas import DataFrame

# print(new_population)

best_outputs = []
weight_list =[]
tsne_df = []
temp_pop = []
fit = []
# fig, ax = plt.subplots( num_generations,1,figsize=(40,50))

for generation in range(num_generations):
    print("Generation : ", generation)
    
    fitness, parent, tsne,weight, temp_population= cal_pop_fitness(dataframe_new,population)
    highest_point = parent
    weight_list.append(weight)
    tsne_df.append(tsne)
    temp_pop.append(temp_population)
    fit.append(fitness)
#     print('highest_point shape: ', highest_point.shape)
#     print("Fitness")
#     print(fitness)
#     print('max fitness: ', max(fitness))
#     print('highest point: ', highest_point)
    
#     parents = select_mating_pool(population, highest_point, num_parents_mating)
#     print("Parents")
#     print(parent)
#     print('offspring size: ' + str(pop_size[0]-highest_point.shape[0]))
    offspring_crossover = crossover(highest_point,
                                       offspring_size=(abs(pop_size[0]-highest_point.shape[0]), num_weights))
#     print("Crossover")
#     print(offspring_crossover)

    offspring_mutation = mutation(offspring_crossover, num_mutations=2)
#     print("Mutation")
#     print(offspring_mutation)

    # Creating the new population based on the parents and offspring.
#     print('offspring_mutation shape: ', offspring_mutation.shape)
   
    dataframe_new.iloc[0:highest_point.shape[0], :] = highest_point.values
    dataframe_new.iloc[highest_point.shape[0]:, :] = offspring_mutation
    
    
from sklearn.ensemble import RandomForestClassifier
d = temp_pop[0]
print(d)
X = d.iloc[:, 0:97]
y = d['Bugs']
forest = RandomForestClassifier(n_estimators=100)
forest.fit(X,y)

feature_imp = pd.Series(forest.feature_importances_,index=data.iloc[:,0:97].columns).sort_values(ascending=False)
print(feature_imp)


feature = DataFrame(feature_imp)
temp_list = []
feature_cols = list(feature.iloc[0:30].index)
for i in range(num_generations):
    temp = temp_pop[i]
    bug = temp['Bugs']
    
    droplist = [i for i in temp.columns if i not in feature_cols]
    temp_new = temp.drop(droplist,axis=1)
    
#     new.dropna(axis=1,inplace=True)
#     new = temp_new
    for column in temp_new.columns:
        temp_new[column] = ((temp_new[column] - temp_new[column].min()) / (temp_new[column].max() - temp_new[column].min()))

    temp_new.fillna(0.0, inplace = True)

    temp_new=temp_new.applymap(lambda x: x + np.random.rand()/20.0)

    new = pd.concat([temp_new, bug],ignore_index=False, sort=False, axis=1) 
    
    plt.figure(figsize=(10, 5))
    plt.title("Plot Number = %.i" % i, fontsize=15)
    sns.scatterplot(x="X", y="Y",hue="bug",data=tsne_df[i])
    
    fig, ax = plt.subplots(figsize=(15, 6))
    pd.plotting.parallel_coordinates(
        new, 'Bugs', color=('blue', 'red'), alpha=0.5, axvlines=False
    )
    
    plt.xticks(rotation=70)
    plt.xlabel("Feature Names")
    plt.ylabel("Values")
    plt.tight_layout()
    plt.title("Finding the Feature Values of Each Data Point")
    L=plt.legend()
    L.get_texts()[0].set_text('Non-Bug')
    L.get_texts()[1].set_text('Bug')
